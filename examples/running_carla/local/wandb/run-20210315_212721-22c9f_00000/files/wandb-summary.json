{"episode_reward_max": 5.4018810899047365, "episode_reward_min": 0.25950000000000006, "episode_reward_mean": 1.9345103188114499, "episode_len_mean": 332.42, "episodes_this_iter": 0, "num_healthy_workers": 1, "timesteps_total": 63600, "episodes_total": 193, "training_iteration": 159, "timestamp": 1615866707, "time_this_iter_s": 30.01005506515503, "time_total_s": 5036.622247219086, "time_since_restore": 5036.622247219086, "timesteps_since_restore": 0, "iterations_since_restore": 159, "sampler_perf/mean_raw_obs_processing_ms": 2.2453282738796476, "sampler_perf/mean_inference_ms": 2.5231067828499407, "sampler_perf/mean_action_processing_ms": 0.15431058801663908, "sampler_perf/mean_env_wait_ms": 72.53444945409433, "sampler_perf/mean_env_render_ms": 0.0, "timers/sample_time_ms": 31269.708, "timers/sample_throughput": 12.792, "timers/learn_time_ms": 712.268, "timers/learn_throughput": 561.587, "timers/update_time_ms": 1.131, "info/num_steps_sampled": 63600, "info/num_steps_trained": 63600, "perf/cpu_util_percent": 29.72954545454546, "perf/ram_util_percent": 8.813636363636364, "info/learner/default_policy/allreduce_latency": 0.0, "info/learner/default_policy/cur_kl_coeff": 0.11559067517414406, "info/learner/default_policy/cur_lr": 5e-05, "info/learner/default_policy/total_loss": -0.029176391661167145, "info/learner/default_policy/policy_loss": -0.03995126858353615, "info/learner/default_policy/vf_loss": 0.008565097698010504, "info/learner/default_policy/vf_explained_var": 0.23032677173614502, "info/learner/default_policy/kl": 0.019117283169180155, "info/learner/default_policy/entropy": 1.1984746754169464, "info/learner/default_policy/entropy_coeff": 0.0, "_step": 158, "_runtime": 5066, "_timestamp": 1615866707}