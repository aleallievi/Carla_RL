{"episode_reward_max": 5.329999999999999, "episode_reward_min": 0.6796888888888889, "episode_reward_mean": 2.1588696759521433, "episode_len_mean": 240.9375, "episodes_this_iter": 16, "num_healthy_workers": 1, "timesteps_total": 4000, "episodes_total": 16, "training_iteration": 1, "timestamp": 1615234007, "time_this_iter_s": 450.3227491378784, "time_total_s": 450.3227491378784, "time_since_restore": 450.3227491378784, "timesteps_since_restore": 0, "iterations_since_restore": 1, "sampler_perf/mean_raw_obs_processing_ms": 2.809248993141119, "sampler_perf/mean_inference_ms": 6.191634678953858, "sampler_perf/mean_action_processing_ms": 0.15235501389240091, "sampler_perf/mean_env_wait_ms": 65.78267410200138, "sampler_perf/mean_env_render_ms": 0.0, "timers/sample_time_ms": 300148.71, "timers/sample_throughput": 13.327, "timers/learn_time_ms": 150151.663, "timers/learn_throughput": 26.64, "timers/update_time_ms": 4.53, "info/num_steps_sampled": 4000, "info/num_steps_trained": 4000, "perf/cpu_util_percent": 28.42877138413686, "perf/ram_util_percent": 6.85692068429238, "info/learner/default_policy/allreduce_latency": 0.0, "info/learner/default_policy/cur_kl_coeff": 0.2, "info/learner/default_policy/cur_lr": 5e-05, "info/learner/default_policy/total_loss": 0.2997129797004163, "info/learner/default_policy/policy_loss": -0.005402295326348394, "info/learner/default_policy/vf_loss": 0.3034122218377888, "info/learner/default_policy/vf_explained_var": 0.23952987790107727, "info/learner/default_policy/kl": 0.00851525460893754, "info/learner/default_policy/entropy": 2.8049383610486984, "info/learner/default_policy/entropy_coeff": 0.0, "_step": 0, "_runtime": 461, "_timestamp": 1615234007}