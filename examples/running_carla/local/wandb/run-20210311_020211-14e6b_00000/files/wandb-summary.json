{"episode_reward_max": 0.14900000000000002, "episode_reward_min": 0.06872500000000001, "episode_reward_mean": 0.14141562500000004, "episode_len_mean": 38.45192307692308, "episodes_this_iter": 104, "num_healthy_workers": 1, "timesteps_total": 136000, "episodes_total": 3510, "training_iteration": 34, "timestamp": 1615465207, "time_this_iter_s": 453.911417722702, "time_total_s": 15464.456790685654, "time_since_restore": 15464.456790685654, "timesteps_since_restore": 0, "iterations_since_restore": 34, "sampler_perf/mean_raw_obs_processing_ms": 15.903538475536179, "sampler_perf/mean_inference_ms": 6.449366671891021, "sampler_perf/mean_action_processing_ms": 0.16871497799034146, "sampler_perf/mean_env_wait_ms": 70.1095645167777, "sampler_perf/mean_env_render_ms": 0.0, "timers/sample_time_ms": 370517.653, "timers/sample_throughput": 10.796, "timers/learn_time_ms": 83696.263, "timers/learn_throughput": 47.792, "timers/update_time_ms": 1.893, "info/num_steps_sampled": 136000, "info/num_steps_trained": 136000, "perf/cpu_util_percent": 13.937557959814528, "perf/ram_util_percent": 9.326893353941268, "info/learner/default_policy/allreduce_latency": 0.0, "info/learner/default_policy/cur_kl_coeff": 0.2, "info/learner/default_policy/cur_lr": 5e-05, "info/learner/default_policy/total_loss": NaN, "info/learner/default_policy/policy_loss": NaN, "info/learner/default_policy/vf_loss": NaN, "info/learner/default_policy/vf_explained_var": null, "info/learner/default_policy/kl": NaN, "info/learner/default_policy/entropy": NaN, "info/learner/default_policy/entropy_coeff": 0.0, "_step": 33, "_runtime": 15476, "_timestamp": 1615465207}