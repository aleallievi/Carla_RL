{"episode_reward_max": 7.839437125149598, "episode_reward_min": 0.48916666666666664, "episode_reward_mean": 3.1805264683390835, "episode_len_mean": 374.85185185185185, "episodes_this_iter": 2, "num_healthy_workers": 1, "timesteps_total": 10121, "episodes_total": 27, "training_iteration": 20, "timestamp": 1615927802, "time_this_iter_s": 59.997137784957886, "time_total_s": 1011.6601536273956, "time_since_restore": 1011.6601536273956, "timesteps_since_restore": 0, "iterations_since_restore": 20, "sampler_perf/mean_raw_obs_processing_ms": 2.087788648943459, "sampler_perf/mean_inference_ms": 6.167229361149128, "sampler_perf/mean_action_processing_ms": 0.14812948338116627, "sampler_perf/mean_env_wait_ms": 66.42877564704766, "sampler_perf/mean_env_render_ms": 0.0, "timers/sample_time_ms": 38625.907, "timers/sample_throughput": 13.141, "timers/learn_time_ms": 12508.717, "timers/learn_throughput": 40.58, "timers/update_time_ms": 2.34, "info/num_steps_sampled": 10121, "info/num_steps_trained": 10121, "perf/cpu_util_percent": 30.084883720930236, "perf/ram_util_percent": 7.799999999999995, "info/learner/default_policy/allreduce_latency": 0.0, "info/learner/default_policy/cur_kl_coeff": 3.4171875, "info/learner/default_policy/cur_lr": 5e-05, "info/learner/default_policy/total_loss": -0.05571802631020546, "info/learner/default_policy/policy_loss": -0.1406342588365078, "info/learner/default_policy/vf_loss": 0.05108058601617813, "info/learner/default_policy/vf_explained_var": 0.9536665081977844, "info/learner/default_policy/kl": 0.009901606291532517, "info/learner/default_policy/entropy": 2.7667399406433106, "info/learner/default_policy/entropy_coeff": 0.0, "_step": 19, "_runtime": 1024, "_timestamp": 1615927802}